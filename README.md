# ğŸ“‚ Ever Growth Data Pipeline: A Power BI Data Engineering Project

A data consolidation and transformation project built to showcase end-to-end data pipeline skills using Power BI. This project focuses on connecting to diverse data sources, performing complex transformations, and building a robust data model for a global sales and distribution company, Ever Growth Enterprises.

## ğŸ“œ Short Description / Purpose

This project addresses the real-world challenge of scattered and inconsistent data storage by demonstrating a data engineering solution using Power BI. It focuses on the crucial first steps of a business intelligence project: **data loading**, **transformation**, and **modeling**, which lay the groundwork for any future analytical reports or dashboards.

---

## ğŸ› ï¸ Tech Stack

This project leverages a powerful suite of tools to handle the entire data preparation workflow:

* **ğŸ“Š Power BI Desktop** â€“ The central platform used for all data ingestion, transformation, and modeling.
* **ğŸ“‚ Power Query** â€“ Utilized extensively for its capabilities in connecting to multiple data sources (folders, JSON, CSV) and performing a wide range of data cleaning and shaping tasks.
* **â„ï¸ Snowflake** â€“ A cloud data warehouse used to simulate a modern data storage environment, showcasing skills in connecting to and importing data from a cloud-based source.
* **ğŸ“ Data Modeling** â€“ The project's core, where relationships were established between a variety of tables to create a star schema, enabling efficient data analysis.
* **ğŸ Python (Optional/Future Work)** â€“ The potential for using Python scripts for more complex data cleaning or automation could be a future enhancement.

---

## ğŸ“‹ Data Sources & Project Flow

The project workflow simulates a common business scenario where data resides in various locations and formats:

1.  **Sellers Data:** Loaded from a local folder, demonstrating the ability to handle multiple files at once.
2.  **Flat Files:** Connections were established to CSV files (**Customers**, **Orders**, **Geolocation**) and a JSON file (**Products**), highlighting proficiency with different file types.
3.  **Snowflake Database:** Data was first loaded into Snowflake tables (**Order Payments**, **Order Items**, **Product Categories**, **Order Reviews**) and then imported into Power BI. This step demonstrates familiarity with cloud data warehousing and data ingestion from a central repository.

---

## âš™ï¸ Key Transformations & Data Modeling

This section highlights the specific data preparation skills demonstrated in the project:

* **Data Loading from Diverse Sources:** The project successfully ingested data from **folders**, **JSON**, **CSV**, and **Snowflake**, showcasing a versatile skill set.
* **Data Cleaning & Manipulation:**
    * Replaced blank values in the `Review comment title` column with "Review not given."
    * Reduced the decimal values in the `PAYMENT_INSTALLMENTS` and `PAYMENTS_VALUE` columns.
* **Date Dimension Creation:** New columns (`Month`, `Year`, `Name of the Month`, `Quarter of the Year`) were derived from the `shipping_LIMIT_DATA` column, a key step in creating a time-intelligence-ready data model.
* **Data Modeling:** The project's highlight is the creation of a well-structured data model, with relationships established between all the tables. A notepad listing the **primary keys** from each table was also created to document the data model's schema.

---

## ğŸ“ Dataset Location

To make this project reproducible, all data and SQL scripts are included in the repository. The folder structure is as follows:
/Ever_Growth_Analytics_Project
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ Ever_Growth_Analytics.pbix
â””â”€â”€ Data/
â”œâ”€â”€ Sellers Data/
â”‚   â”œâ”€â”€ seller_1.csv
â”‚   â””â”€â”€ seller_2.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Flat Files/
â”‚   â”œâ”€â”€ JSON File/
â”‚   â”‚   â””â”€â”€ products_data.json
â”‚   â””â”€â”€ CSV Files/
â”‚       â”œâ”€â”€ customers_data.csv
â”‚       â”œâ”€â”€ orders_data.csv
â”‚       â””â”€â”€ geolocation_data.csv
â””â”€â”€ SQL/
â”œâ”€â”€ create_tables.sql
â””â”€â”€ load_data.sql
